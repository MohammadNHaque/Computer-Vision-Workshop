{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of categories that can be classified by MobileNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = { 0: 'background',\n",
    "    1: 'aeroplane', 2: 'bicycle', 3: 'bird', 4: 'boat',\n",
    "    5: 'bottle', 6: 'bus', 7: 'car', 8: 'cat', 9: 'chair',\n",
    "    10: 'cow', 11: 'diningtable', 12: 'dog', 13: 'horse',\n",
    "    14: 'motorbike', 15: 'person', 16: 'pottedplant',\n",
    "    17: 'sheep', 18: 'sofa', 19: 'train', 20: 'tvmonitor' }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the pre-trained model using opencv dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromCaffe('MobileNetSSD_deploy.prototxt.txt', 'MobileNetSSD_deploy.caffemodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# randomly selecting color for the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.random.uniform(255, 0, size=(len(categories), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read input video\n",
    "# cap = cv2.VideoCapture('walking.avi')\n",
    "\"\"\"\n",
    "use cap = cv2.VideoCapture(0), for webcam\n",
    "\"\"\" \n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    # read each frame of the video\n",
    "    ret, image = cap.read()\n",
    "    # SSD accepts image size of (300,300). Resize the images\n",
    "    resized_image = cv2.resize(image,(300,300))\n",
    "    # create a blob of an image and normalize the image\n",
    "    blob = cv2.dnn.blobFromImage(resized_image, 0.007843, (300, 300), (127.5, 127.5, 127.5), False)\n",
    "    # feed blob to the model\n",
    "    net.setInput(blob)\n",
    "    # result from the model\n",
    "    detections = net.forward()\n",
    "    # to caculate scale factor\n",
    "    (h, w) = resized_image.shape[:2]\n",
    "    # iterate over all the detection result\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        # select if probability of detection is greater than 20%\n",
    "        if confidence > 0.2: \n",
    "            class_id = int(detections[0, 0, i, 1])\n",
    "            # postion of the detected object in sacled image\n",
    "            startX = int(detections[0, 0, i, 3] * w) \n",
    "            startY = int(detections[0, 0, i, 4] * h)\n",
    "            endX   = int(detections[0, 0, i, 5] * w)\n",
    "            endY   = int(detections[0, 0, i, 6] * h)\n",
    "            heightFactor = image.shape[0]/300.0  \n",
    "            widthFactor = image.shape[1]/300.0 \n",
    "            # map position of the detected object into original image\n",
    "            startX = int(widthFactor * startX) \n",
    "            startY = int(heightFactor * startY)\n",
    "            endX   = int(widthFactor * endX)\n",
    "            endY   = int(heightFactor * endY)\n",
    "            # draw rectangular box around each object  \n",
    "            cv2.rectangle(image, (startX, startY), (endX, endY), (0, 255, 0))\n",
    "            if class_id in categories:\n",
    "                label = categories[class_id] + \": \" + str(confidence)\n",
    "                labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "                startY = max(startY, labelSize[1])\n",
    "                cv2.rectangle(image, (startX, startY - labelSize[1]), (startX + labelSize[0], startY + baseLine), \n",
    "                              (0, 255, 0), cv2.FILLED)\n",
    "                # write label of the object on the image\n",
    "                cv2.putText(image, label, (startX, startY), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255))\n",
    "    cv2.imshow(\"object detection result\", image)\n",
    "    # destroy the window by pressing key 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
